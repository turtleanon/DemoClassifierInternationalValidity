{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPcpnHJ1wZrjQRULvpodF7S"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"qj7-WcjvLosf"},"outputs":[],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","import os\n","import ast\n","from glob import glob\n","from sklearn import metrics\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns"]},{"cell_type":"markdown","source":["The performance of 3 models are analyzed under their respective header in this notebook (i.e., CheXpert-trained, MIMIC-trained, NIH-trained models)"],"metadata":{"id":"58wRdH61vIui"}},{"cell_type":"markdown","source":["# CheXpert"],"metadata":{"id":"REb-UPtRLunb"}},{"cell_type":"code","source":["import pandas as pd\n","import ast\n","from sklearn import metrics\n","from sklearn.preprocessing import LabelEncoder\n","# Standardized race/ethnicity categories\n","STANDARD_RACES = ['Hispanic/Latino', 'Non-Hispanic Asian', 'Non-Hispanic Black',  'Non-Hispanic White']\n","\n","# Mapping from original labels to standardized labels\n","RACE_STANDARDIZATION = {\n","    'Asian': 'Non-Hispanic Asian',\n","    'Non-Hispanic Asian': 'Non-Hispanic Asian',\n","    'Black': 'Non-Hispanic Black',\n","    'Non-Hispanic Black': 'Non-Hispanic Black',\n","    'Hispanic/Latino': 'Hispanic/Latino',\n","    'Other': 'Other',\n","    'White': 'Non-Hispanic White',\n","    'Non-Hispanic White': 'Non-Hispanic White'\n","}\n","\n","def evaluate_race_csv(csv_file_path, label_name):\n","    try:\n","        predict_df = pd.read_csv(csv_file_path)\n","\n","        # Parse the stringified list into a real list\n","        predict_df['Race/Ethnicity_Probability'] = predict_df['Race/Ethnicity_Probability'].apply(ast.literal_eval)\n","        predict_df['Race/Ethnicity'] = predict_df['Race/Ethnicity'].map(RACE_STANDARDIZATION)\n","        predict_df = predict_df[predict_df['Race/Ethnicity'] != 'Other']\n","\n","        # Encode the textual labels into integers\n","        label_encoder = LabelEncoder()\n","        y_true = label_encoder.fit_transform(predict_df['Race/Ethnicity'])\n","\n","        # Get the list of probabilities\n","        y_score = predict_df['Race/Ethnicity_Probability'].tolist()\n","\n","        # Compute weighted AUROC\n","        wAUROC = metrics.roc_auc_score(\n","            y_true,\n","            y_score,\n","            multi_class='ovr',\n","            average='weighted'\n","        )\n","\n","        # Compute weighted AUPRC\n","        wAUPRC = metrics.average_precision_score(\n","            y_true,\n","            y_score,\n","            average='weighted'\n","        )\n","\n","        print(f'{label_name} - wAUROC: {wAUROC:.4f}, wAUPRC: {wAUPRC:.4f}')\n","\n","    except (FileNotFoundError, KeyError, ValueError) as e:\n","        print(f\"Error processing {csv_file_path}: {e}\")\n","\n","# Define files and labels\n","csv_files_with_labels = [\n","    ('/content/chexpert_race2_chexpert_test.csv', 'CheXpert'),\n","    ('/content/chexpert_race2_mimic_test.csv', 'MIMIC')\n","]\n","\n","# Run evaluations\n","for file_path, label in csv_files_with_labels:\n","    evaluate_race_csv(file_path, label)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zjz20ndxLuSe","executionInfo":{"status":"ok","timestamp":1748643681328,"user_tz":240,"elapsed":2833,"user":{"displayName":"Preetham Bachina","userId":"11894630684993396878"}},"outputId":"1a0c0bad-f1f4-4613-bf7b-961de16928f6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CheXpert - wAUROC: 0.8931, wAUPRC: 0.8367\n","MIMIC - wAUROC: 0.9133, wAUPRC: 0.8824\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import ast\n","from sklearn import metrics\n","from sklearn.preprocessing import LabelEncoder\n","import numpy as np\n","\n","# Standardized race/ethnicity categories\n","STANDARD_RACES = ['Hispanic/Latino', 'Non-Hispanic Asian', 'Non-Hispanic Black',  'Non-Hispanic White']\n","\n","# Mapping from original labels to standardized labels\n","RACE_STANDARDIZATION = {\n","    'Asian': 'Non-Hispanic Asian',\n","    'Non-Hispanic Asian': 'Non-Hispanic Asian',\n","    'Black': 'Non-Hispanic Black',\n","    'Non-Hispanic Black': 'Non-Hispanic Black',\n","    'Hispanic/Latino': 'Hispanic/Latino',\n","    'Other': 'Other',\n","    'White': 'Non-Hispanic White',\n","    'Non-Hispanic White': 'Non-Hispanic White'\n","}\n","\n","def evaluate_race_csv(csv_file_path, label_name):\n","    try:\n","        predict_df = pd.read_csv(csv_file_path)\n","\n","        # Parse the stringified list into a real list\n","        predict_df['Race/Ethnicity_Probability'] = predict_df['Race/Ethnicity_Probability'].apply(ast.literal_eval)\n","        predict_df['Race/Ethnicity'] = predict_df['Race/Ethnicity'].map(RACE_STANDARDIZATION)\n","        predict_df = predict_df[predict_df['Race/Ethnicity'] != 'Other']\n","\n","\n","        # Encode the textual labels into integers\n","        label_encoder = LabelEncoder()\n","        y_true = label_encoder.fit_transform(predict_df['Race/Ethnicity'])\n","        classes = label_encoder.classes_\n","\n","        # Get the list of probabilities and convert to numpy array\n","        y_score = np.array(predict_df['Race/Ethnicity_Probability'].tolist())\n","\n","        # Calculate class prevalences (weights)\n","        class_counts = np.bincount(y_true)\n","        class_weights = class_counts / len(y_true)\n","\n","        # Initialize lists to store per-class metrics\n","        auroc_scores = []\n","        auprc_scores = []\n","\n","        # Compute metrics for each class using one-vs-rest approach\n","        for class_idx in range(len(classes)):\n","            # Create binary labels for current class\n","            y_true_binary = (y_true == class_idx).astype(int)\n","\n","            # Get probabilities for current class\n","            y_score_class = y_score[:, class_idx]\n","\n","            # Compute AUROC\n","            if len(np.unique(y_true_binary)) >= 2:  # Need at least one positive and one negative sample\n","                auroc = metrics.roc_auc_score(y_true_binary, y_score_class)\n","                auroc_scores.append(auroc)\n","            else:\n","                auroc_scores.append(np.nan)\n","\n","            # Compute AUPRC\n","            auprc = metrics.average_precision_score(y_true_binary, y_score_class)\n","            auprc_scores.append(auprc)\n","\n","        # Calculate manually weighted averages (ignoring NaN values)\n","        valid_auroc = ~np.isnan(auroc_scores)\n","        weighted_auroc = np.sum(np.array(auroc_scores)[valid_auroc] * class_weights[valid_auroc]) / np.sum(class_weights[valid_auroc])\n","\n","        weighted_auprc = np.sum(np.array(auprc_scores) * class_weights) / np.sum(class_weights)\n","\n","        # Print results\n","        print(f'\\n{label_name} Results:')\n","        print('Class\\t\\tPrevalence\\tAUROC\\t\\tAUPRC')\n","        for i, class_name in enumerate(classes):\n","            print(f'{class_name:<15}{class_weights[i]:.4f}\\t\\t{auroc_scores[i]:.4f}\\t\\t{auprc_scores[i]:.4f}')\n","\n","        print(f'\\n{label_name} - Manually Weighted Average - wAUROC: {weighted_auroc:.4f}, wAUPRC: {weighted_auprc:.4f}')\n","\n","    except (FileNotFoundError, KeyError, ValueError) as e:\n","        print(f\"Error processing {csv_file_path}: {e}\")\n","\n","# Define files and labels\n","csv_files_with_labels = [\n","    ('/content/chexpert_race2_chexpert_test.csv', 'CheXpert'),\n","    ('/content/chexpert_race2_mimic_test.csv', 'MIMIC')\n","]\n","\n","# Run evaluations\n","for file_path, label in csv_files_with_labels:\n","    evaluate_race_csv(file_path, label)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TQzJVVWSPGlx","executionInfo":{"status":"ok","timestamp":1748643683480,"user_tz":240,"elapsed":2151,"user":{"displayName":"Preetham Bachina","userId":"11894630684993396878"}},"outputId":"6c9d8441-5cf3-4a6b-8530-7140dc15abc6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","CheXpert Results:\n","Class\t\tPrevalence\tAUROC\t\tAUPRC\n","Hispanic/Latino0.1360\t\t0.8057\t\t0.4892\n","Non-Hispanic Asian0.1432\t\t0.9290\t\t0.7646\n","Non-Hispanic Black0.0573\t\t0.9491\t\t0.6827\n","Non-Hispanic White0.6635\t\t0.8984\t\t0.9368\n","\n","CheXpert - Manually Weighted Average - wAUROC: 0.8931, wAUPRC: 0.8367\n","\n","MIMIC Results:\n","Class\t\tPrevalence\tAUROC\t\tAUPRC\n","Hispanic/Latino0.0549\t\t0.6975\t\t0.1714\n","Non-Hispanic Asian0.0383\t\t0.9436\t\t0.6549\n","Non-Hispanic Black0.1764\t\t0.9466\t\t0.8227\n","Non-Hispanic White0.7303\t\t0.9199\t\t0.9623\n","\n","MIMIC - Manually Weighted Average - wAUROC: 0.9133, wAUPRC: 0.8824\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import ast\n","from sklearn import metrics\n","from sklearn.preprocessing import LabelEncoder\n","import numpy as np\n","\n","STANDARD_RACES = ['Hispanic/Latino', 'Non-Hispanic Asian', 'Non-Hispanic Black',  'Non-Hispanic White']\n","RACE_STANDARDIZATION = {\n","    'Asian': 'Non-Hispanic Asian',\n","    'Non-Hispanic Asian': 'Non-Hispanic Asian',\n","    'Black': 'Non-Hispanic Black',\n","    'Non-Hispanic Black': 'Non-Hispanic Black',\n","    'Hispanic/Latino': 'Hispanic/Latino',\n","    'Other': 'Other',\n","    'White': 'Non-Hispanic White',\n","    'Non-Hispanic White': 'Non-Hispanic White'\n","}\n","\n","def bootstrap_race_metrics(csv_file_path, label_name, n_iterations=1000, random_state=2025):\n","    try:\n","        df = pd.read_csv(csv_file_path)\n","        df['Race/Ethnicity_Probability'] = df['Race/Ethnicity_Probability'].apply(ast.literal_eval)\n","        df['Race/Ethnicity'] = df['Race/Ethnicity'].map(RACE_STANDARDIZATION)\n","        df = df[df['Race/Ethnicity'] != 'Other'].copy()\n","\n","        label_encoder = LabelEncoder()\n","        y_true_all = label_encoder.fit_transform(df['Race/Ethnicity'])\n","        y_score_all = np.array(df['Race/Ethnicity_Probability'].tolist())\n","        classes = label_encoder.classes_\n","        n_classes = len(classes)\n","\n","        data = pd.DataFrame({'y_true': y_true_all.tolist(), 'y_score': y_score_all.tolist()})\n","        rng = np.random.default_rng(seed=random_state)\n","\n","        auroc_bootstrap = []\n","        auprc_bootstrap = []\n","\n","        for _ in range(n_iterations):\n","            sample = data.sample(n=len(data), replace=True, random_state=rng.integers(1e9))\n","            y_true = np.array(sample['y_true'].tolist())\n","            y_score = np.array(sample['y_score'].tolist())\n","\n","            auroc_scores = []\n","            auprc_scores = []\n","            class_counts = np.bincount(y_true, minlength=n_classes)\n","            class_weights = class_counts / len(y_true)\n","\n","            for class_idx in range(n_classes):\n","                y_true_binary = (y_true == class_idx).astype(int)\n","                y_score_class = y_score[:, class_idx]\n","\n","                if len(np.unique(y_true_binary)) >= 2:\n","                    auroc = metrics.roc_auc_score(y_true_binary, y_score_class)\n","                else:\n","                    auroc = np.nan\n","                auprc = metrics.average_precision_score(y_true_binary, y_score_class)\n","\n","                auroc_scores.append(auroc)\n","                auprc_scores.append(auprc)\n","\n","            # Weighted average ignoring NaN in AUROC\n","            valid_auroc = ~np.isnan(auroc_scores)\n","            weighted_auroc = np.sum(np.array(auroc_scores)[valid_auroc] * class_weights[valid_auroc]) / np.sum(class_weights[valid_auroc])\n","            weighted_auprc = np.sum(np.array(auprc_scores) * class_weights) / np.sum(class_weights)\n","\n","            auroc_bootstrap.append(weighted_auroc)\n","            auprc_bootstrap.append(weighted_auprc)\n","\n","        # Compute confidence intervals\n","        auroc_ci = np.percentile(auroc_bootstrap, [2.5, 97.5])\n","        auprc_ci = np.percentile(auprc_bootstrap, [2.5, 97.5])\n","\n","        print(f\"\\n{label_name} - Bootstrapped Weighted Metrics:\")\n","        print(f\"wAUROC 95% CI: [{auroc_ci[0]:.4f}, {auroc_ci[1]:.4f}]\")\n","        print(f\"wAUPRC 95% CI: [{auprc_ci[0]:.4f}, {auprc_ci[1]:.4f}]\")\n","\n","        return auroc_ci, auprc_ci\n","\n","    except (FileNotFoundError, KeyError, ValueError) as e:\n","        print(f\"Error processing {csv_file_path}: {e}\")\n","        return None, None\n","\n","\n","# Run bootstrap evaluation\n","csv_files_with_labels = [\n","    ('/content/chexpert_race2_chexpert_test.csv', 'CheXpert'),\n","    ('/content/chexpert_race2_mimic_test.csv', 'MIMIC')\n","]\n","\n","for file_path, label in csv_files_with_labels:\n","    bootstrap_race_metrics(file_path, label)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xl1DX4YlH21N","executionInfo":{"status":"ok","timestamp":1748643918515,"user_tz":240,"elapsed":235033,"user":{"displayName":"Preetham Bachina","userId":"11894630684993396878"}},"outputId":"2a0902ca-8e68-4a77-ec31-8c5833e8377f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","CheXpert - Bootstrapped Weighted Metrics:\n","wAUROC 95% CI: [0.8895, 0.8965]\n","wAUPRC 95% CI: [0.8323, 0.8414]\n","\n","MIMIC - Bootstrapped Weighted Metrics:\n","wAUROC 95% CI: [0.9101, 0.9162]\n","wAUPRC 95% CI: [0.8789, 0.8863]\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import ast\n","from sklearn import metrics\n","from sklearn.preprocessing import LabelEncoder\n","import numpy as np\n","\n","STANDARD_RACES = ['Hispanic/Latino', 'Non-Hispanic Asian', 'Non-Hispanic Black',  'Non-Hispanic White']\n","RACE_STANDARDIZATION = {\n","    'Asian': 'Non-Hispanic Asian',\n","    'Non-Hispanic Asian': 'Non-Hispanic Asian',\n","    'Black': 'Non-Hispanic Black',\n","    'Non-Hispanic Black': 'Non-Hispanic Black',\n","    'Hispanic/Latino': 'Hispanic/Latino',\n","    'Other': 'Other',\n","    'White': 'Non-Hispanic White',\n","    'Non-Hispanic White': 'Non-Hispanic White'\n","}\n","\n","def bootstrap_race_metrics(csv_file_path, label_name, n_iterations=1000, random_state=2025):\n","    try:\n","        df = pd.read_csv(csv_file_path)\n","        df['Race/Ethnicity_Probability'] = df['Race/Ethnicity_Probability'].apply(ast.literal_eval)\n","        df['Race/Ethnicity'] = df['Race/Ethnicity'].map(RACE_STANDARDIZATION)\n","        df = df[df['Race/Ethnicity'] != 'Other'].copy()\n","\n","        label_encoder = LabelEncoder()\n","        y_true_all = label_encoder.fit_transform(df['Race/Ethnicity'])\n","        y_score_all = np.array(df['Race/Ethnicity_Probability'].tolist())\n","        classes = label_encoder.classes_\n","        n_classes = len(classes)\n","\n","        data = pd.DataFrame({'y_true': y_true_all.tolist(), 'y_score': y_score_all.tolist()})\n","        rng = np.random.default_rng(seed=random_state)\n","\n","        auroc_bootstrap = []\n","        auprc_bootstrap = []\n","        per_class_aurocs = [[] for _ in range(n_classes)]\n","\n","        for _ in range(n_iterations):\n","            sample = data.sample(n=len(data), replace=True, random_state=rng.integers(1e9))\n","            y_true = np.array(sample['y_true'].tolist())\n","            y_score = np.array(sample['y_score'].tolist())\n","\n","            auroc_scores = []\n","            auprc_scores = []\n","            class_counts = np.bincount(y_true, minlength=n_classes)\n","            class_weights = class_counts / len(y_true)\n","\n","            for class_idx in range(n_classes):\n","                y_true_binary = (y_true == class_idx).astype(int)\n","                y_score_class = y_score[:, class_idx]\n","\n","                if len(np.unique(y_true_binary)) >= 2:\n","                    auroc = metrics.roc_auc_score(y_true_binary, y_score_class)\n","                else:\n","                    auroc = np.nan\n","                auprc = metrics.average_precision_score(y_true_binary, y_score_class)\n","\n","                auroc_scores.append(auroc)\n","                auprc_scores.append(auprc)\n","\n","                # Store for per-class CI\n","                per_class_aurocs[class_idx].append(auroc)\n","\n","            valid_auroc = ~np.isnan(auroc_scores)\n","            weighted_auroc = np.sum(np.array(auroc_scores)[valid_auroc] * class_weights[valid_auroc]) / np.sum(class_weights[valid_auroc])\n","            weighted_auprc = np.sum(np.array(auprc_scores) * class_weights) / np.sum(class_weights)\n","\n","            auroc_bootstrap.append(weighted_auroc)\n","            auprc_bootstrap.append(weighted_auprc)\n","\n","        auroc_ci = np.percentile(auroc_bootstrap, [2.5, 97.5])\n","        auprc_ci = np.percentile(auprc_bootstrap, [2.5, 97.5])\n","\n","        print(f\"\\n{label_name} - Bootstrapped Weighted Metrics:\")\n","        print(f\"wAUROC 95% CI: [{auroc_ci[0]:.4f}, {auroc_ci[1]:.4f}]\")\n","        print(f\"wAUPRC 95% CI: [{auprc_ci[0]:.4f}, {auprc_ci[1]:.4f}]\\n\")\n","\n","        # Per-class AUROC confidence intervals\n","        print(f\"{label_name} - Per-Class AUROC 95% CIs:\")\n","        for i, class_name in enumerate(classes):\n","            class_aurocs = np.array(per_class_aurocs[i])\n","            class_aurocs = class_aurocs[~np.isnan(class_aurocs)]\n","            if len(class_aurocs) == 0:\n","                print(f\"{class_name:<25} Insufficient data for AUROC\")\n","            else:\n","                ci = np.percentile(class_aurocs, [2.5, 97.5])\n","                print(f\"{class_name:<25} AUROC 95% CI: [{ci[0]:.4f}, {ci[1]:.4f}]\")\n","\n","        return auroc_ci, auprc_ci\n","\n","    except (FileNotFoundError, KeyError, ValueError) as e:\n","        print(f\"Error processing {csv_file_path}: {e}\")\n","        return None, None\n","\n","# Run bootstrap evaluation\n","csv_files_with_labels = [\n","    ('/content/chexpert_race2_chexpert_test.csv', 'CheXpert'),\n","    ('/content/chexpert_race2_mimic_test.csv', 'MIMIC')\n","]\n","\n","for file_path, label in csv_files_with_labels:\n","    bootstrap_race_metrics(file_path, label)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lhy3bJgDQ35I","executionInfo":{"status":"ok","timestamp":1748644152521,"user_tz":240,"elapsed":234008,"user":{"displayName":"Preetham Bachina","userId":"11894630684993396878"}},"outputId":"f356d34b-13f1-48e9-9c98-368909b0e041"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","CheXpert - Bootstrapped Weighted Metrics:\n","wAUROC 95% CI: [0.8895, 0.8965]\n","wAUPRC 95% CI: [0.8323, 0.8414]\n","\n","CheXpert - Per-Class AUROC 95% CIs:\n","Hispanic/Latino           AUROC 95% CI: [0.7979, 0.8130]\n","Non-Hispanic Asian        AUROC 95% CI: [0.9247, 0.9334]\n","Non-Hispanic Black        AUROC 95% CI: [0.9442, 0.9542]\n","Non-Hispanic White        AUROC 95% CI: [0.8944, 0.9020]\n","\n","MIMIC - Bootstrapped Weighted Metrics:\n","wAUROC 95% CI: [0.9101, 0.9162]\n","wAUPRC 95% CI: [0.8789, 0.8863]\n","\n","MIMIC - Per-Class AUROC 95% CIs:\n","Hispanic/Latino           AUROC 95% CI: [0.6855, 0.7102]\n","Non-Hispanic Asian        AUROC 95% CI: [0.9375, 0.9496]\n","Non-Hispanic Black        AUROC 95% CI: [0.9438, 0.9493]\n","Non-Hispanic White        AUROC 95% CI: [0.9163, 0.9231]\n"]}]},{"cell_type":"markdown","source":["# MIMIC"],"metadata":{"id":"ZH6Jst0bLwt-"}},{"cell_type":"code","source":["import pandas as pd\n","import ast\n","from sklearn import metrics\n","from sklearn.preprocessing import LabelEncoder\n","\n","\n","def evaluate_race_csv(csv_file_path, label_name):\n","    try:\n","        predict_df = pd.read_csv(csv_file_path)\n","\n","        # Parse the stringified list into a real list\n","        predict_df['Race/Ethnicity_Probability'] = predict_df['Race/Ethnicity_Probability'].apply(ast.literal_eval)\n","\n","        # Encode the textual labels into integers\n","        label_encoder = LabelEncoder()\n","        y_true = label_encoder.fit_transform(predict_df['Race/Ethnicity'])\n","\n","        # Get the list of probabilities\n","        y_score = predict_df['Race/Ethnicity_Probability'].tolist()\n","\n","        # Compute weighted AUROC\n","        wAUROC = metrics.roc_auc_score(\n","            y_true,\n","            y_score,\n","            multi_class='ovr',\n","            average='weighted'\n","        )\n","\n","        # Compute weighted AUPRC\n","        wAUPRC = metrics.average_precision_score(\n","            y_true,\n","            y_score,\n","            average='weighted'\n","        )\n","\n","        print(f'{label_name} - wAUROC: {wAUROC:.4f}, wAUPRC: {wAUPRC:.4f}')\n","\n","    except (FileNotFoundError, KeyError, ValueError) as e:\n","        print(f\"Error processing {csv_file_path}: {e}\")\n","\n","# Define files and labels\n","csv_files_with_labels = [\n","    ('/content/mimic_race_mimic_test.csv', 'MIMIC')\n","]\n","\n","# Run evaluations\n","for file_path, label in csv_files_with_labels:\n","    evaluate_race_csv(file_path, label)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sbeKWFjxNpFo","executionInfo":{"status":"ok","timestamp":1748644153752,"user_tz":240,"elapsed":1232,"user":{"displayName":"Preetham Bachina","userId":"11894630684993396878"}},"outputId":"b40f8f63-c996-456a-a29a-bdc4ab54706f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["MIMIC - wAUROC: 0.9046, wAUPRC: 0.8439\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import ast\n","from sklearn import metrics\n","from sklearn.preprocessing import LabelEncoder\n","import numpy as np\n","\n","# Standardized race/ethnicity categories\n","STANDARD_RACES = ['Asian', 'Black', 'Hispanic/Latino', 'Other', 'White']\n","\n","# Mapping from original labels to standardized labels\n","RACE_STANDARDIZATION = {\n","    'Asian': 'Asian',\n","    'Non-Hispanic Asian': 'Asian',\n","    'Black': 'Black',\n","    'Non-Hispanic Black': 'Black',\n","    'Hispanic/Latino': 'Hispanic/Latino',\n","    'Other': 'Other',\n","    'White': 'White',\n","    'Non-Hispanic White': 'White'\n","}\n","\n","def evaluate_race_csv(csv_file_path, label_name):\n","    try:\n","        predict_df = pd.read_csv(csv_file_path)\n","\n","        # Parse probabilities and standardize race labels\n","        predict_df['Race/Ethnicity_Probability'] = predict_df['Race/Ethnicity_Probability'].apply(ast.literal_eval)\n","        predict_df['Race/Ethnicity'] = predict_df['Race/Ethnicity'].map(RACE_STANDARDIZATION)\n","        # Encode the textual labels into integers\n","        label_encoder = LabelEncoder()\n","        y_true = label_encoder.fit_transform(predict_df['Race/Ethnicity'])\n","        classes = label_encoder.classes_\n","\n","        # Get the list of probabilities and convert to numpy array\n","        y_score = np.array(predict_df['Race/Ethnicity_Probability'].tolist())\n","\n","        # Calculate class prevalences (weights)\n","        class_counts = np.bincount(y_true)\n","        class_weights = class_counts / len(y_true)\n","\n","        # Initialize lists to store per-class metrics\n","        auroc_scores = []\n","        auprc_scores = []\n","\n","        # Compute metrics for each class using one-vs-rest approach\n","        for class_idx in range(len(classes)):\n","          if class_idx == 3 and label_name == 'CheXpert':\n","            # Create binary labels for current class\n","            y_true_binary = (y_true == 3).astype(int)\n","\n","            # Get probabilities for current class\n","            y_score_class = y_score[:, 4]\n","\n","            # Compute AUROC\n","            if len(np.unique(y_true_binary)) >= 2:  # Need at least one positive and one negative sample\n","                auroc = metrics.roc_auc_score(y_true_binary, y_score_class)\n","                auroc_scores.append(auroc)\n","            else:\n","                auroc_scores.append(np.nan)\n","            auprc = metrics.average_precision_score(y_true_binary, y_score_class)\n","            auprc_scores.append(auprc)\n","          else:\n","            # Create binary labels for current class\n","            y_true_binary = (y_true == class_idx).astype(int)\n","\n","            # Get probabilities for current class\n","            y_score_class = y_score[:, class_idx]\n","\n","            # Compute AUROC\n","            if len(np.unique(y_true_binary)) >= 2:  # Need at least one positive and one negative sample\n","                auroc = metrics.roc_auc_score(y_true_binary, y_score_class)\n","                auroc_scores.append(auroc)\n","            else:\n","                auroc_scores.append(np.nan)\n","\n","            # Compute AUPRC\n","            auprc = metrics.average_precision_score(y_true_binary, y_score_class)\n","            auprc_scores.append(auprc)\n","\n","        # Calculate manually weighted averages (ignoring NaN values)\n","        valid_auroc = ~np.isnan(auroc_scores)\n","        weighted_auroc = np.sum(np.array(auroc_scores)[valid_auroc] * class_weights[valid_auroc]) / np.sum(class_weights[valid_auroc])\n","\n","        weighted_auprc = np.sum(np.array(auprc_scores) * class_weights) / np.sum(class_weights)\n","\n","        # Print results\n","        print(f'\\n{label_name} Results:')\n","        print('Class\\t\\tPrevalence\\tAUROC\\t\\tAUPRC')\n","        for i, class_name in enumerate(classes):\n","            print(f'{class_name:<15}{class_weights[i]:.4f}\\t\\t{auroc_scores[i]:.4f}\\t\\t{auprc_scores[i]:.4f}')\n","\n","        print(f'\\n{label_name} - Manually Weighted Average - wAUROC: {weighted_auroc:.4f}, wAUPRC: {weighted_auprc:.4f}')\n","\n","    except (FileNotFoundError, KeyError, ValueError) as e:\n","        print(f\"Error processing {csv_file_path}: {e}\")\n","\n","# Define files and labels\n","csv_files_with_labels = [\n","    ('/content/mimic_race_chexpert_race_v2_test.csv', 'CheXpert'),\n","    ('/content/mimic_race_mimic_test.csv', 'MIMIC')\n","]\n","\n","# Run evaluations\n","for file_path, label in csv_files_with_labels:\n","    evaluate_race_csv(file_path, label)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H9joY0jBRzBB","executionInfo":{"status":"ok","timestamp":1748644155925,"user_tz":240,"elapsed":2172,"user":{"displayName":"Preetham Bachina","userId":"11894630684993396878"}},"outputId":"f042b09f-eb60-4254-9fcd-b2a3daf99904"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","CheXpert Results:\n","Class\t\tPrevalence\tAUROC\t\tAUPRC\n","Asian          0.1432\t\t0.8565\t\t0.5727\n","Black          0.0573\t\t0.9222\t\t0.5933\n","Hispanic/Latino0.1360\t\t0.7098\t\t0.2902\n","White          0.6635\t\t0.8349\t\t0.8933\n","\n","CheXpert - Manually Weighted Average - wAUROC: 0.8259, wAUPRC: 0.7481\n","\n","MIMIC Results:\n","Class\t\tPrevalence\tAUROC\t\tAUPRC\n","Asian          0.0372\t\t0.9246\t\t0.5131\n","Black          0.1711\t\t0.9487\t\t0.8121\n","Hispanic/Latino0.0533\t\t0.7892\t\t0.1988\n","Other          0.0301\t\t0.6410\t\t0.0517\n","White          0.7083\t\t0.9128\t\t0.9511\n","\n","MIMIC - Manually Weighted Average - wAUROC: 0.9046, wAUPRC: 0.8439\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import ast\n","from sklearn import metrics\n","from sklearn.preprocessing import LabelEncoder\n","import numpy as np\n","\n","# Standardized race/ethnicity categories\n","STANDARD_RACES = ['Asian', 'Black', 'Hispanic/Latino', 'Other', 'White']\n","\n","# Mapping from original labels to standardized labels\n","RACE_STANDARDIZATION = {\n","    'Asian': 'Asian',\n","    'Non-Hispanic Asian': 'Asian',\n","    'Black': 'Black',\n","    'Non-Hispanic Black': 'Black',\n","    'Hispanic/Latino': 'Hispanic/Latino',\n","    'Other': 'Other',\n","    'White': 'White',\n","    'Non-Hispanic White': 'White'\n","}\n","\n","def bootstrap_race_metrics(csv_file_path, label_name, n_iterations=1000, random_state=2025):\n","    try:\n","        df = pd.read_csv(csv_file_path)\n","        df['Race/Ethnicity_Probability'] = df['Race/Ethnicity_Probability'].apply(ast.literal_eval)\n","        df['Race/Ethnicity'] = df['Race/Ethnicity'].map(RACE_STANDARDIZATION)\n","        label_encoder = LabelEncoder()\n","        y_true_all = label_encoder.fit_transform(df['Race/Ethnicity'])\n","        y_score_all = np.array(df['Race/Ethnicity_Probability'].tolist())\n","        classes = label_encoder.classes_\n","        n_classes = len(classes)\n","\n","        data = pd.DataFrame({'y_true': y_true_all.tolist(), 'y_score': y_score_all.tolist()})\n","        rng = np.random.default_rng(seed=random_state)\n","\n","        auroc_bootstrap = []\n","        auprc_bootstrap = []\n","\n","        for _ in range(n_iterations):\n","            sample = data.sample(n=len(data), replace=True, random_state=rng.integers(1e9))\n","            y_true = np.array(sample['y_true'].tolist())\n","            y_score = np.array(sample['y_score'].tolist())\n","\n","            auroc_scores = []\n","            auprc_scores = []\n","            class_counts = np.bincount(y_true, minlength=n_classes)\n","            class_weights = class_counts / len(y_true)\n","\n","            for class_idx in range(n_classes):\n","                y_true_binary = (y_true == class_idx).astype(int)\n","\n","                # Special case for CheXpert \"Other\" class index 3\n","                if class_idx == 3 and label_name == 'CheXpert':\n","                    y_score_class = y_score[:, 4]\n","                else:\n","                    y_score_class = y_score[:, class_idx]\n","\n","                if len(np.unique(y_true_binary)) >= 2:\n","                    auroc = metrics.roc_auc_score(y_true_binary, y_score_class)\n","                else:\n","                    auroc = np.nan\n","                auprc = metrics.average_precision_score(y_true_binary, y_score_class)\n","\n","                auroc_scores.append(auroc)\n","                auprc_scores.append(auprc)\n","\n","            valid_auroc = ~np.isnan(auroc_scores)\n","            weighted_auroc = np.sum(np.array(auroc_scores)[valid_auroc] * class_weights[valid_auroc]) / np.sum(class_weights[valid_auroc])\n","            weighted_auprc = np.sum(np.array(auprc_scores) * class_weights) / np.sum(class_weights)\n","\n","            auroc_bootstrap.append(weighted_auroc)\n","            auprc_bootstrap.append(weighted_auprc)\n","\n","        auroc_ci = np.percentile(auroc_bootstrap, [2.5, 97.5])\n","        auprc_ci = np.percentile(auprc_bootstrap, [2.5, 97.5])\n","\n","        print(f\"\\n{label_name} - Bootstrapped Weighted Metrics:\")\n","        print(f\"wAUROC 95% CI: [{auroc_ci[0]:.4f}, {auroc_ci[1]:.4f}]\")\n","        print(f\"wAUPRC 95% CI: [{auprc_ci[0]:.4f}, {auprc_ci[1]:.4f}]\")\n","\n","        return auroc_ci, auprc_ci\n","\n","    except (FileNotFoundError, KeyError, ValueError) as e:\n","        print(f\"Error processing {csv_file_path}: {e}\")\n","        return None, None\n","\n","\n","# Run bootstrap evaluation on your new files\n","csv_files_with_labels = [\n","    ('/content/mimic_race_chexpert_race_v2_test.csv', 'CheXpert'),\n","    ('/content/mimic_race_mimic_test.csv', 'MIMIC')\n","]\n","\n","for path, label in csv_files_with_labels:\n","    bootstrap_race_metrics(path, label)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CWAVxkn2I12C","executionInfo":{"status":"ok","timestamp":1748644436736,"user_tz":240,"elapsed":280803,"user":{"displayName":"Preetham Bachina","userId":"11894630684993396878"}},"outputId":"c6205bcf-de60-4253-e27b-d6a393ec22f3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","CheXpert - Bootstrapped Weighted Metrics:\n","wAUROC 95% CI: [0.8210, 0.8304]\n","wAUPRC 95% CI: [0.7425, 0.7540]\n","\n","MIMIC - Bootstrapped Weighted Metrics:\n","wAUROC 95% CI: [0.9015, 0.9078]\n","wAUPRC 95% CI: [0.8401, 0.8480]\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import ast\n","from sklearn import metrics\n","from sklearn.preprocessing import LabelEncoder\n","import numpy as np\n","\n","# Standardized race/ethnicity categories\n","STANDARD_RACES = ['Asian', 'Black', 'Hispanic/Latino', 'Other', 'White']\n","\n","# Mapping from original labels to standardized labels\n","RACE_STANDARDIZATION = {\n","    'Asian': 'Asian',\n","    'Non-Hispanic Asian': 'Asian',\n","    'Black': 'Black',\n","    'Non-Hispanic Black': 'Black',\n","    'Hispanic/Latino': 'Hispanic/Latino',\n","    'Other': 'Other',\n","    'White': 'White',\n","    'Non-Hispanic White': 'White'\n","}\n","\n","def bootstrap_race_metrics(csv_file_path, label_name, n_iterations=1000, random_state=2025):\n","    try:\n","        df = pd.read_csv(csv_file_path)\n","        df['Race/Ethnicity_Probability'] = df['Race/Ethnicity_Probability'].apply(ast.literal_eval)\n","        df['Race/Ethnicity'] = df['Race/Ethnicity'].map(RACE_STANDARDIZATION)\n","        label_encoder = LabelEncoder()\n","        y_true_all = label_encoder.fit_transform(df['Race/Ethnicity'])\n","        y_score_all = np.array(df['Race/Ethnicity_Probability'].tolist())\n","        classes = label_encoder.classes_\n","        n_classes = len(classes)\n","\n","        data = pd.DataFrame({'y_true': y_true_all.tolist(), 'y_score': y_score_all.tolist()})\n","        rng = np.random.default_rng(seed=random_state)\n","\n","        # Store AUROC and AUPRC for weighted and each class\n","        auroc_bootstrap = []\n","        auprc_bootstrap = []\n","        per_class_aurocs = [[] for _ in range(n_classes)]\n","\n","        for _ in range(n_iterations):\n","            sample = data.sample(n=len(data), replace=True, random_state=rng.integers(1e9))\n","            y_true = np.array(sample['y_true'].tolist())\n","            y_score = np.array(sample['y_score'].tolist())\n","\n","            auroc_scores = []\n","            auprc_scores = []\n","            class_counts = np.bincount(y_true, minlength=n_classes)\n","            class_weights = class_counts / len(y_true)\n","\n","            for class_idx in range(n_classes):\n","                y_true_binary = (y_true == class_idx).astype(int)\n","\n","                # Special case for CheXpert \"Other\" class index 3\n","                if class_idx == 3 and label_name == 'CheXpert':\n","                    y_score_class = y_score[:, 4]\n","                else:\n","                    y_score_class = y_score[:, class_idx]\n","\n","                if len(np.unique(y_true_binary)) >= 2:\n","                    auroc = metrics.roc_auc_score(y_true_binary, y_score_class)\n","                else:\n","                    auroc = np.nan\n","                auprc = metrics.average_precision_score(y_true_binary, y_score_class)\n","\n","                auroc_scores.append(auroc)\n","                auprc_scores.append(auprc)\n","\n","                # Collect for CI computation\n","                per_class_aurocs[class_idx].append(auroc)\n","\n","            valid_auroc = ~np.isnan(auroc_scores)\n","            weighted_auroc = np.sum(np.array(auroc_scores)[valid_auroc] * class_weights[valid_auroc]) / np.sum(class_weights[valid_auroc])\n","            weighted_auprc = np.sum(np.array(auprc_scores) * class_weights) / np.sum(class_weights)\n","\n","            auroc_bootstrap.append(weighted_auroc)\n","            auprc_bootstrap.append(weighted_auprc)\n","\n","        # Compute weighted CIs\n","        auroc_ci = np.percentile(auroc_bootstrap, [2.5, 97.5])\n","        auprc_ci = np.percentile(auprc_bootstrap, [2.5, 97.5])\n","\n","        print(f\"\\n{label_name} - Bootstrapped Weighted Metrics:\")\n","        print(f\"wAUROC 95% CI: [{auroc_ci[0]:.4f}, {auroc_ci[1]:.4f}]\")\n","        print(f\"wAUPRC 95% CI: [{auprc_ci[0]:.4f}, {auprc_ci[1]:.4f}]\")\n","\n","        # Compute and print per-class AUROC CIs\n","        print(f\"\\n{label_name} - Per-Class AUROC 95% Confidence Intervals:\")\n","        for i, class_name in enumerate(classes):\n","            class_aurocs = [x for x in per_class_aurocs[i] if not np.isnan(x)]\n","            if len(class_aurocs) > 0:\n","                ci_low, ci_high = np.percentile(class_aurocs, [2.5, 97.5])\n","                print(f\"{class_name:<20}: [{ci_low:.4f}, {ci_high:.4f}]\")\n","            else:\n","                print(f\"{class_name:<20}: AUROC CI not computable (insufficient variation)\")\n","\n","        return auroc_ci, auprc_ci\n","\n","    except (FileNotFoundError, KeyError, ValueError) as e:\n","        print(f\"Error processing {csv_file_path}: {e}\")\n","        return None, None\n","\n","\n","# Run bootstrap evaluation\n","csv_files_with_labels = [\n","    ('/content/mimic_race_chexpert_race_v2_test.csv', 'CheXpert'),\n","    ('/content/mimic_race_mimic_test.csv', 'MIMIC')\n","]\n","\n","for path, label in csv_files_with_labels:\n","    bootstrap_race_metrics(path, label)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8hZu1-YaRP4p","executionInfo":{"status":"ok","timestamp":1748644717963,"user_tz":240,"elapsed":281230,"user":{"displayName":"Preetham Bachina","userId":"11894630684993396878"}},"outputId":"1874acc2-9912-4527-8a1d-fa09a819a581"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","CheXpert - Bootstrapped Weighted Metrics:\n","wAUROC 95% CI: [0.8210, 0.8304]\n","wAUPRC 95% CI: [0.7425, 0.7540]\n","\n","CheXpert - Per-Class AUROC 95% Confidence Intervals:\n","Asian               : [0.8506, 0.8631]\n","Black               : [0.9152, 0.9290]\n","Hispanic/Latino     : [0.7014, 0.7179]\n","White               : [0.8296, 0.8396]\n","\n","MIMIC - Bootstrapped Weighted Metrics:\n","wAUROC 95% CI: [0.9015, 0.9078]\n","wAUPRC 95% CI: [0.8401, 0.8480]\n","\n","MIMIC - Per-Class AUROC 95% Confidence Intervals:\n","Asian               : [0.9187, 0.9311]\n","Black               : [0.9462, 0.9512]\n","Hispanic/Latino     : [0.7799, 0.7978]\n","Other               : [0.6250, 0.6558]\n","White               : [0.9095, 0.9160]\n"]}]},{"cell_type":"markdown","source":["# We also trained a classifier on CheXpert where only non-Hispanic Asian, non-Hispanic Black and non-Hispanic White individuals were included. These are the results"],"metadata":{"id":"1qNsZAntYgwF"}},{"cell_type":"markdown","source":["# CheXpert"],"metadata":{"id":"m749_JEwY77U"}},{"cell_type":"code","source":["import pandas as pd\n","import ast\n","from sklearn import metrics\n","from sklearn.preprocessing import LabelEncoder\n","# Standardized race/ethnicity categories\n","STANDARD_RACES = ['Hispanic/Latino', 'Non-Hispanic Asian', 'Non-Hispanic Black',  'Non-Hispanic White']\n","\n","# Mapping from original labels to standardized labels\n","RACE_STANDARDIZATION = {\n","    'Asian': 'Non-Hispanic Asian',\n","    'Non-Hispanic Asian': 'Non-Hispanic Asian',\n","    'Black': 'Non-Hispanic Black',\n","    'Non-Hispanic Black': 'Non-Hispanic Black',\n","    'Hispanic/Latino': 'Hispanic/Latino',\n","    'Other': 'Other',\n","    'White': 'Non-Hispanic White',\n","    'Non-Hispanic White': 'Non-Hispanic White'\n","}\n","\n","def evaluate_race_csv(csv_file_path, label_name):\n","    try:\n","        predict_df = pd.read_csv(csv_file_path)\n","\n","        # Parse the stringified list into a real list\n","        predict_df['Race/Ethnicity_Probability'] = predict_df['Race/Ethnicity_Probability'].apply(ast.literal_eval)\n","        predict_df['Race/Ethnicity'] = predict_df['Race/Ethnicity'].map(RACE_STANDARDIZATION)\n","        predict_df = predict_df[predict_df['Race/Ethnicity'] != 'Other']\n","        predict_df = predict_df[predict_df['Race/Ethnicity'] != 'Hispanic/Latino']\n","\n","        # Encode the textual labels into integers\n","        label_encoder = LabelEncoder()\n","        y_true = label_encoder.fit_transform(predict_df['Race/Ethnicity'])\n","\n","        # Get the list of probabilities\n","        y_score = predict_df['Race/Ethnicity_Probability'].tolist()\n","\n","        # Compute weighted AUROC\n","        wAUROC = metrics.roc_auc_score(\n","            y_true,\n","            y_score,\n","            multi_class='ovr',\n","            average='weighted'\n","        )\n","\n","        # Compute weighted AUPRC\n","        wAUPRC = metrics.average_precision_score(\n","            y_true,\n","            y_score,\n","            average='weighted'\n","        )\n","\n","        print(f'{label_name} - wAUROC: {wAUROC:.4f}, wAUPRC: {wAUPRC:.4f}')\n","\n","    except (FileNotFoundError, KeyError, ValueError) as e:\n","        print(f\"Error processing {csv_file_path}: {e}\")\n","\n","# Define files and labels\n","csv_files_with_labels = [\n","    ('/content/chexpert_race1_chexpert_test.csv', 'CheXpert'),\n","    ('/content/chexpert_race1_mimic_test.csv', 'MIMIC')\n","]\n","\n","# Run evaluations\n","for file_path, label in csv_files_with_labels:\n","    evaluate_race_csv(file_path, label)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0DGR9eueYqeg","executionInfo":{"status":"ok","timestamp":1748644720353,"user_tz":240,"elapsed":2392,"user":{"displayName":"Preetham Bachina","userId":"11894630684993396878"}},"outputId":"64984c7c-8b69-4811-b73d-d6adba9860cd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CheXpert - wAUROC: 0.9362, wAUPRC: 0.9312\n","MIMIC - wAUROC: 0.9490, wAUPRC: 0.9454\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import ast\n","from sklearn import metrics\n","from sklearn.preprocessing import LabelEncoder\n","import numpy as np\n","\n","# Standardized race/ethnicity categories\n","STANDARD_RACES = ['Hispanic/Latino', 'Non-Hispanic Asian', 'Non-Hispanic Black',  'Non-Hispanic White']\n","\n","# Mapping from original labels to standardized labels\n","RACE_STANDARDIZATION = {\n","    'Asian': 'Non-Hispanic Asian',\n","    'Non-Hispanic Asian': 'Non-Hispanic Asian',\n","    'Black': 'Non-Hispanic Black',\n","    'Non-Hispanic Black': 'Non-Hispanic Black',\n","    'Hispanic/Latino': 'Hispanic/Latino',\n","    'Other': 'Other',\n","    'White': 'Non-Hispanic White',\n","    'Non-Hispanic White': 'Non-Hispanic White'\n","}\n","\n","def evaluate_race_csv(csv_file_path, label_name):\n","    try:\n","        predict_df = pd.read_csv(csv_file_path)\n","\n","        # Parse the stringified list into a real list\n","        predict_df['Race/Ethnicity_Probability'] = predict_df['Race/Ethnicity_Probability'].apply(ast.literal_eval)\n","        predict_df['Race/Ethnicity'] = predict_df['Race/Ethnicity'].map(RACE_STANDARDIZATION)\n","        predict_df = predict_df[predict_df['Race/Ethnicity'] != 'Other']\n","        predict_df = predict_df[predict_df['Race/Ethnicity'] != 'Hispanic/Latino']\n","\n","\n","        # Encode the textual labels into integers\n","        label_encoder = LabelEncoder()\n","        y_true = label_encoder.fit_transform(predict_df['Race/Ethnicity'])\n","        classes = label_encoder.classes_\n","\n","        # Get the list of probabilities and convert to numpy array\n","        y_score = np.array(predict_df['Race/Ethnicity_Probability'].tolist())\n","\n","        # Calculate class prevalences (weights)\n","        class_counts = np.bincount(y_true)\n","        class_weights = class_counts / len(y_true)\n","\n","        # Initialize lists to store per-class metrics\n","        auroc_scores = []\n","        auprc_scores = []\n","\n","        # Compute metrics for each class using one-vs-rest approach\n","        for class_idx in range(len(classes)):\n","            # Create binary labels for current class\n","            y_true_binary = (y_true == class_idx).astype(int)\n","\n","            # Get probabilities for current class\n","            y_score_class = y_score[:, class_idx]\n","\n","            # Compute AUROC\n","            if len(np.unique(y_true_binary)) >= 2:  # Need at least one positive and one negative sample\n","                auroc = metrics.roc_auc_score(y_true_binary, y_score_class)\n","                auroc_scores.append(auroc)\n","            else:\n","                auroc_scores.append(np.nan)\n","\n","            # Compute AUPRC\n","            auprc = metrics.average_precision_score(y_true_binary, y_score_class)\n","            auprc_scores.append(auprc)\n","\n","        # Calculate manually weighted averages (ignoring NaN values)\n","        valid_auroc = ~np.isnan(auroc_scores)\n","        weighted_auroc = np.sum(np.array(auroc_scores)[valid_auroc] * class_weights[valid_auroc]) / np.sum(class_weights[valid_auroc])\n","\n","        weighted_auprc = np.sum(np.array(auprc_scores) * class_weights) / np.sum(class_weights)\n","\n","        # Print results\n","        print(f'\\n{label_name} Results:')\n","        print('Class\\t\\tPrevalence\\tAUROC\\t\\tAUPRC')\n","        for i, class_name in enumerate(classes):\n","            print(f'{class_name:<15}{class_weights[i]:.4f}\\t\\t{auroc_scores[i]:.4f}\\t\\t{auprc_scores[i]:.4f}')\n","\n","        print(f'\\n{label_name} - Manually Weighted Average - wAUROC: {weighted_auroc:.4f}, wAUPRC: {weighted_auprc:.4f}')\n","\n","    except (FileNotFoundError, KeyError, ValueError) as e:\n","        print(f\"Error processing {csv_file_path}: {e}\")\n","\n","# Define files and labels\n","csv_files_with_labels = [\n","    ('/content/chexpert_race1_chexpert_test.csv', 'CheXpert'),\n","    ('/content/chexpert_race1_mimic_test.csv', 'MIMIC')\n","]\n","\n","# Run evaluations\n","for file_path, label in csv_files_with_labels:\n","    evaluate_race_csv(file_path, label)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zn-6qbp5ZMwh","executionInfo":{"status":"ok","timestamp":1748644722325,"user_tz":240,"elapsed":1967,"user":{"displayName":"Preetham Bachina","userId":"11894630684993396878"}},"outputId":"7d298f55-f050-4405-da53-3d3b1c1fa0d0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","CheXpert Results:\n","Class\t\tPrevalence\tAUROC\t\tAUPRC\n","Non-Hispanic Asian0.1702\t\t0.9435\t\t0.8318\n","Non-Hispanic Black0.0722\t\t0.9293\t\t0.7120\n","Non-Hispanic White0.7576\t\t0.9353\t\t0.9744\n","\n","CheXpert - Manually Weighted Average - wAUROC: 0.9362, wAUPRC: 0.9312\n","\n","MIMIC Results:\n","Class\t\tPrevalence\tAUROC\t\tAUPRC\n","Non-Hispanic Asian0.0406\t\t0.9325\t\t0.6014\n","Non-Hispanic Black0.1867\t\t0.9533\t\t0.8680\n","Non-Hispanic White0.7727\t\t0.9489\t\t0.9822\n","\n","MIMIC - Manually Weighted Average - wAUROC: 0.9490, wAUPRC: 0.9454\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import ast\n","from sklearn import metrics\n","from sklearn.preprocessing import LabelEncoder\n","import numpy as np\n","\n","# Standardized race/ethnicity categories\n","STANDARD_RACES = ['Non-Hispanic Asian', 'Non-Hispanic Black',  'Non-Hispanic White']\n","\n","# Mapping from original labels to standardized labels\n","RACE_STANDARDIZATION = {\n","    'Asian': 'Non-Hispanic Asian',\n","    'Non-Hispanic Asian': 'Non-Hispanic Asian',\n","    'Black': 'Non-Hispanic Black',\n","    'Non-Hispanic Black': 'Non-Hispanic Black',\n","    'Hispanic/Latino': 'Other',\n","    'Other': 'Other',\n","    'White': 'Non-Hispanic White',\n","    'Non-Hispanic White': 'Non-Hispanic White'\n","}\n","\n","def bootstrap_race_metrics(csv_file_path, label_name, n_iterations=1000, random_state=2025):\n","    try:\n","        df = pd.read_csv(csv_file_path)\n","        df['Race/Ethnicity_Probability'] = df['Race/Ethnicity_Probability'].apply(ast.literal_eval)\n","        df['Race/Ethnicity'] = df['Race/Ethnicity'].map(RACE_STANDARDIZATION)\n","        df = df[df['Race/Ethnicity'] != 'Other'].copy()\n","\n","        label_encoder = LabelEncoder()\n","        y_true_all = label_encoder.fit_transform(df['Race/Ethnicity'])\n","        y_score_all = np.array(df['Race/Ethnicity_Probability'].tolist())\n","        classes = label_encoder.classes_\n","        n_classes = len(classes)\n","\n","        data = pd.DataFrame({'y_true': y_true_all.tolist(), 'y_score': y_score_all.tolist()})\n","        rng = np.random.default_rng(seed=random_state)\n","\n","        auroc_bootstrap = []\n","        auprc_bootstrap = []\n","\n","        for _ in range(n_iterations):\n","            sample = data.sample(n=len(data), replace=True, random_state=rng.integers(1e9))\n","            y_true = np.array(sample['y_true'].tolist())\n","            y_score = np.array(sample['y_score'].tolist())\n","\n","            auroc_scores = []\n","            auprc_scores = []\n","            class_counts = np.bincount(y_true, minlength=n_classes)\n","            class_weights = class_counts / len(y_true)\n","\n","            for class_idx in range(n_classes):\n","                y_true_binary = (y_true == class_idx).astype(int)\n","                y_score_class = y_score[:, class_idx]\n","\n","                if len(np.unique(y_true_binary)) >= 2:\n","                    auroc = metrics.roc_auc_score(y_true_binary, y_score_class)\n","                else:\n","                    auroc = np.nan\n","                auprc = metrics.average_precision_score(y_true_binary, y_score_class)\n","\n","                auroc_scores.append(auroc)\n","                auprc_scores.append(auprc)\n","\n","            # Weighted average ignoring NaN in AUROC\n","            valid_auroc = ~np.isnan(auroc_scores)\n","            weighted_auroc = np.sum(np.array(auroc_scores)[valid_auroc] * class_weights[valid_auroc]) / np.sum(class_weights[valid_auroc])\n","            weighted_auprc = np.sum(np.array(auprc_scores) * class_weights) / np.sum(class_weights)\n","\n","            auroc_bootstrap.append(weighted_auroc)\n","            auprc_bootstrap.append(weighted_auprc)\n","\n","        # Compute confidence intervals\n","        auroc_ci = np.percentile(auroc_bootstrap, [2.5, 97.5])\n","        auprc_ci = np.percentile(auprc_bootstrap, [2.5, 97.5])\n","\n","        print(f\"\\n{label_name} - Bootstrapped Weighted Metrics:\")\n","        print(f\"wAUROC 95% CI: [{auroc_ci[0]:.4f}, {auroc_ci[1]:.4f}]\")\n","        print(f\"wAUPRC 95% CI: [{auprc_ci[0]:.4f}, {auprc_ci[1]:.4f}]\")\n","\n","        return auroc_ci, auprc_ci\n","\n","    except (FileNotFoundError, KeyError, ValueError) as e:\n","        print(f\"Error processing {csv_file_path}: {e}\")\n","        return None, None\n","\n","\n","# Run bootstrap evaluation\n","csv_files_with_labels = [\n","    ('/content/chexpert_race1_chexpert_test.csv', 'CheXpert'),\n","    ('/content/chexpert_race1_mimic_test.csv', 'MIMIC')\n","]\n","\n","for file_path, label in csv_files_with_labels:\n","    bootstrap_race_metrics(file_path, label)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yF5ZKci2KjNp","executionInfo":{"status":"ok","timestamp":1748644893686,"user_tz":240,"elapsed":171363,"user":{"displayName":"Preetham Bachina","userId":"11894630684993396878"}},"outputId":"899448c2-406d-4b88-916f-76452c604f90"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","CheXpert - Bootstrapped Weighted Metrics:\n","wAUROC 95% CI: [0.9327, 0.9396]\n","wAUPRC 95% CI: [0.9280, 0.9345]\n","\n","MIMIC - Bootstrapped Weighted Metrics:\n","wAUROC 95% CI: [0.9466, 0.9513]\n","wAUPRC 95% CI: [0.9433, 0.9477]\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import ast\n","from sklearn import metrics\n","from sklearn.preprocessing import LabelEncoder\n","import numpy as np\n","\n","# Standardized race/ethnicity categories\n","STANDARD_RACES = ['Non-Hispanic Asian', 'Non-Hispanic Black',  'Non-Hispanic White']\n","\n","# Mapping from original labels to standardized labels\n","RACE_STANDARDIZATION = {\n","    'Asian': 'Non-Hispanic Asian',\n","    'Non-Hispanic Asian': 'Non-Hispanic Asian',\n","    'Black': 'Non-Hispanic Black',\n","    'Non-Hispanic Black': 'Non-Hispanic Black',\n","    'Hispanic/Latino': 'Other',\n","    'Other': 'Other',\n","    'White': 'Non-Hispanic White',\n","    'Non-Hispanic White': 'Non-Hispanic White'\n","}\n","\n","def bootstrap_race_metrics(csv_file_path, label_name, n_iterations=1000, random_state=2025):\n","    try:\n","        df = pd.read_csv(csv_file_path)\n","        df['Race/Ethnicity_Probability'] = df['Race/Ethnicity_Probability'].apply(ast.literal_eval)\n","        df['Race/Ethnicity'] = df['Race/Ethnicity'].map(RACE_STANDARDIZATION)\n","        df = df[df['Race/Ethnicity'] != 'Other'].copy()\n","\n","        label_encoder = LabelEncoder()\n","        y_true_all = label_encoder.fit_transform(df['Race/Ethnicity'])\n","        y_score_all = np.array(df['Race/Ethnicity_Probability'].tolist())\n","        classes = label_encoder.classes_\n","        n_classes = len(classes)\n","\n","        data = pd.DataFrame({'y_true': y_true_all.tolist(), 'y_score': y_score_all.tolist()})\n","        rng = np.random.default_rng(seed=random_state)\n","\n","        auroc_bootstrap = []\n","        auprc_bootstrap = []\n","        per_class_aurocs = [[] for _ in range(n_classes)]\n","\n","        for _ in range(n_iterations):\n","            sample = data.sample(n=len(data), replace=True, random_state=rng.integers(1e9))\n","            y_true = np.array(sample['y_true'].tolist())\n","            y_score = np.array(sample['y_score'].tolist())\n","\n","            auroc_scores = []\n","            auprc_scores = []\n","            class_counts = np.bincount(y_true, minlength=n_classes)\n","            class_weights = class_counts / len(y_true)\n","\n","            for class_idx in range(n_classes):\n","                y_true_binary = (y_true == class_idx).astype(int)\n","                y_score_class = y_score[:, class_idx]\n","\n","                if len(np.unique(y_true_binary)) >= 2:\n","                    auroc = metrics.roc_auc_score(y_true_binary, y_score_class)\n","                else:\n","                    auroc = np.nan\n","                auprc = metrics.average_precision_score(y_true_binary, y_score_class)\n","\n","                auroc_scores.append(auroc)\n","                auprc_scores.append(auprc)\n","\n","                # Store for per-class CI\n","                per_class_aurocs[class_idx].append(auroc)\n","\n","            valid_auroc = ~np.isnan(auroc_scores)\n","            weighted_auroc = np.sum(np.array(auroc_scores)[valid_auroc] * class_weights[valid_auroc]) / np.sum(class_weights[valid_auroc])\n","            weighted_auprc = np.sum(np.array(auprc_scores) * class_weights) / np.sum(class_weights)\n","\n","            auroc_bootstrap.append(weighted_auroc)\n","            auprc_bootstrap.append(weighted_auprc)\n","\n","        auroc_ci = np.percentile(auroc_bootstrap, [2.5, 97.5])\n","        auprc_ci = np.percentile(auprc_bootstrap, [2.5, 97.5])\n","\n","        print(f\"\\n{label_name} - Bootstrapped Weighted Metrics:\")\n","        print(f\"wAUROC 95% CI: [{auroc_ci[0]:.4f}, {auroc_ci[1]:.4f}]\")\n","        print(f\"wAUPRC 95% CI: [{auprc_ci[0]:.4f}, {auprc_ci[1]:.4f}]\\n\")\n","\n","        # Per-class AUROC confidence intervals\n","        print(f\"{label_name} - Per-Class AUROC 95% CIs:\")\n","        for i, class_name in enumerate(classes):\n","            class_aurocs = np.array(per_class_aurocs[i])\n","            class_aurocs = class_aurocs[~np.isnan(class_aurocs)]\n","            if len(class_aurocs) == 0:\n","                print(f\"{class_name:<25} Insufficient data for AUROC\")\n","            else:\n","                ci = np.percentile(class_aurocs, [2.5, 97.5])\n","                print(f\"{class_name:<25} AUROC 95% CI: [{ci[0]:.4f}, {ci[1]:.4f}]\")\n","\n","        return auroc_ci, auprc_ci\n","\n","    except (FileNotFoundError, KeyError, ValueError) as e:\n","        print(f\"Error processing {csv_file_path}: {e}\")\n","        return None, None\n","\n","\n","# Run bootstrap evaluation\n","csv_files_with_labels = [\n","    ('/content/chexpert_race1_chexpert_test.csv', 'CheXpert'),\n","    ('/content/chexpert_race1_mimic_test.csv', 'MIMIC')\n","]\n","\n","for file_path, label in csv_files_with_labels:\n","    bootstrap_race_metrics(file_path, label)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CDzOOdTOR0jm","executionInfo":{"status":"ok","timestamp":1748645068840,"user_tz":240,"elapsed":175155,"user":{"displayName":"Preetham Bachina","userId":"11894630684993396878"}},"outputId":"5f6b9a5a-7e18-46b2-a86d-e12b35387115"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","CheXpert - Bootstrapped Weighted Metrics:\n","wAUROC 95% CI: [0.9327, 0.9396]\n","wAUPRC 95% CI: [0.9280, 0.9345]\n","\n","CheXpert - Per-Class AUROC 95% CIs:\n","Non-Hispanic Asian        AUROC 95% CI: [0.9397, 0.9470]\n","Non-Hispanic Black        AUROC 95% CI: [0.9223, 0.9360]\n","Non-Hispanic White        AUROC 95% CI: [0.9317, 0.9387]\n","\n","MIMIC - Bootstrapped Weighted Metrics:\n","wAUROC 95% CI: [0.9466, 0.9513]\n","wAUPRC 95% CI: [0.9433, 0.9477]\n","\n","MIMIC - Per-Class AUROC 95% CIs:\n","Non-Hispanic Asian        AUROC 95% CI: [0.9256, 0.9389]\n","Non-Hispanic Black        AUROC 95% CI: [0.9508, 0.9559]\n","Non-Hispanic White        AUROC 95% CI: [0.9464, 0.9514]\n"]}]},{"cell_type":"markdown","source":["# MIMIC"],"metadata":{"id":"dAK73ftGZbfr"}},{"cell_type":"code","source":["import pandas as pd\n","import ast\n","from sklearn import metrics\n","from sklearn.preprocessing import LabelEncoder\n","import numpy as np\n","\n","# Standardized race/ethnicity categories\n","STANDARD_RACES = ['Asian', 'Black', 'Hispanic/Latino', 'Other', 'White']\n","\n","# Mapping from original labels to standardized labels\n","RACE_STANDARDIZATION = {\n","    'Asian': 'Asian',\n","    'Non-Hispanic Asian': 'Asian',\n","    'Black': 'Black',\n","    'Non-Hispanic Black': 'Black',\n","    'Hispanic/Latino': 'Hispanic/Latino',\n","    'Other': 'Other',\n","    'White': 'White',\n","    'Non-Hispanic White': 'White'\n","}\n","\n","def evaluate_race_csv(csv_file_path, label_name):\n","    try:\n","        predict_df = pd.read_csv(csv_file_path)\n","\n","        # Parse probabilities and standardize race labels\n","        predict_df['Race/Ethnicity_Probability'] = predict_df['Race/Ethnicity_Probability'].apply(ast.literal_eval)\n","        predict_df['Race/Ethnicity'] = predict_df['Race/Ethnicity'].map(RACE_STANDARDIZATION)\n","        # Encode the textual labels into integers\n","        label_encoder = LabelEncoder()\n","        y_true = label_encoder.fit_transform(predict_df['Race/Ethnicity'])\n","        classes = label_encoder.classes_\n","\n","        # Get the list of probabilities and convert to numpy array\n","        y_score = np.array(predict_df['Race/Ethnicity_Probability'].tolist())\n","\n","        # Calculate class prevalences (weights)\n","        class_counts = np.bincount(y_true)\n","        class_weights = class_counts / len(y_true)\n","\n","        # Initialize lists to store per-class metrics\n","        auroc_scores = []\n","        auprc_scores = []\n","\n","        # Compute metrics for each class using one-vs-rest approach\n","        for class_idx in range(len(classes)):\n","          if class_idx == 2 and label_name == 'CheXpert':\n","            # Create binary labels for current class\n","            y_true_binary = (y_true == 2).astype(int)\n","\n","            # Get probabilities for current class\n","            y_score_class = y_score[:, 4]\n","\n","            # Compute AUROC\n","            if len(np.unique(y_true_binary)) >= 2:  # Need at least one positive and one negative sample\n","                auroc = metrics.roc_auc_score(y_true_binary, y_score_class)\n","                auroc_scores.append(auroc)\n","            else:\n","                auroc_scores.append(np.nan)\n","            auprc = metrics.average_precision_score(y_true_binary, y_score_class)\n","            auprc_scores.append(auprc)\n","          else:\n","            # Create binary labels for current class\n","            y_true_binary = (y_true == class_idx).astype(int)\n","\n","            # Get probabilities for current class\n","            y_score_class = y_score[:, class_idx]\n","\n","            # Compute AUROC\n","            if len(np.unique(y_true_binary)) >= 2:  # Need at least one positive and one negative sample\n","                auroc = metrics.roc_auc_score(y_true_binary, y_score_class)\n","                auroc_scores.append(auroc)\n","            else:\n","                auroc_scores.append(np.nan)\n","\n","            # Compute AUPRC\n","            auprc = metrics.average_precision_score(y_true_binary, y_score_class)\n","            auprc_scores.append(auprc)\n","\n","        # Calculate manually weighted averages (ignoring NaN values)\n","        valid_auroc = ~np.isnan(auroc_scores)\n","        weighted_auroc = np.sum(np.array(auroc_scores)[valid_auroc] * class_weights[valid_auroc]) / np.sum(class_weights[valid_auroc])\n","\n","        weighted_auprc = np.sum(np.array(auprc_scores) * class_weights) / np.sum(class_weights)\n","\n","        # Print results\n","        print(f'\\n{label_name} Results:')\n","        print('Class\\t\\tPrevalence\\tAUROC\\t\\tAUPRC')\n","        for i, class_name in enumerate(classes):\n","            print(f'{class_name:<15}{class_weights[i]:.4f}\\t\\t{auroc_scores[i]:.4f}\\t\\t{auprc_scores[i]:.4f}')\n","\n","        print(f'\\n{label_name} - Manually Weighted Average - wAUROC: {weighted_auroc:.4f}, wAUPRC: {weighted_auprc:.4f}')\n","\n","    except (FileNotFoundError, KeyError, ValueError) as e:\n","        print(f\"Error processing {csv_file_path}: {e}\")\n","\n","# Define files and labels\n","csv_files_with_labels = [\n","    ('/content/mimic_race_chexpert_race_v1_test.csv', 'CheXpert')\n","]\n","\n","# Run evaluations\n","for file_path, label in csv_files_with_labels:\n","    evaluate_race_csv(file_path, label)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NBsetbEJZcZE","executionInfo":{"status":"ok","timestamp":1748645069859,"user_tz":240,"elapsed":1019,"user":{"displayName":"Preetham Bachina","userId":"11894630684993396878"}},"outputId":"ae1dd092-90ad-4154-a757-b59951be0d6d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","CheXpert Results:\n","Class\t\tPrevalence\tAUROC\t\tAUPRC\n","Asian          0.1702\t\t0.8773\t\t0.6741\n","Black          0.0722\t\t0.9119\t\t0.6481\n","White          0.7576\t\t0.8740\t\t0.9481\n","\n","CheXpert - Manually Weighted Average - wAUROC: 0.8773, wAUPRC: 0.8798\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import ast\n","from sklearn import metrics\n","from sklearn.preprocessing import LabelEncoder\n","import numpy as np\n","\n","# Standardized race/ethnicity categories\n","STANDARD_RACES = ['Asian', 'Black', 'Hispanic/Latino', 'Other', 'White']\n","\n","# Mapping from original labels to standardized labels\n","RACE_STANDARDIZATION = {\n","    'Asian': 'Asian',\n","    'Non-Hispanic Asian': 'Asian',\n","    'Black': 'Black',\n","    'Non-Hispanic Black': 'Black',\n","    'Hispanic/Latino': 'Hispanic/Latino',\n","    'Other': 'Other',\n","    'White': 'White',\n","    'Non-Hispanic White': 'White'\n","}\n","\n","def bootstrap_race_metrics(csv_file_path, label_name, n_iterations=1000, random_state=2025):\n","    try:\n","        df = pd.read_csv(csv_file_path)\n","        df['Race/Ethnicity_Probability'] = df['Race/Ethnicity_Probability'].apply(ast.literal_eval)\n","        df['Race/Ethnicity'] = df['Race/Ethnicity'].map(RACE_STANDARDIZATION)\n","        label_encoder = LabelEncoder()\n","        y_true_all = label_encoder.fit_transform(df['Race/Ethnicity'])\n","        y_score_all = np.array(df['Race/Ethnicity_Probability'].tolist())\n","        classes = label_encoder.classes_\n","        n_classes = len(classes)\n","\n","        data = pd.DataFrame({'y_true': y_true_all.tolist(), 'y_score': y_score_all.tolist()})\n","        rng = np.random.default_rng(seed=random_state)\n","\n","        auroc_bootstrap = []\n","        auprc_bootstrap = []\n","\n","        for _ in range(n_iterations):\n","            sample = data.sample(n=len(data), replace=True, random_state=rng.integers(1e9))\n","            y_true = np.array(sample['y_true'].tolist())\n","            y_score = np.array(sample['y_score'].tolist())\n","\n","            auroc_scores = []\n","            auprc_scores = []\n","            class_counts = np.bincount(y_true, minlength=n_classes)\n","            class_weights = class_counts / len(y_true)\n","\n","            for class_idx in range(n_classes):\n","                y_true_binary = (y_true == class_idx).astype(int)\n","\n","                # Special case for CheXpert \"Other\" class index 3\n","                if class_idx == 2 and label_name == 'CheXpert':\n","                    y_score_class = y_score[:, 4]\n","                else:\n","                    y_score_class = y_score[:, class_idx]\n","\n","                if len(np.unique(y_true_binary)) >= 2:\n","                    auroc = metrics.roc_auc_score(y_true_binary, y_score_class)\n","                else:\n","                    auroc = np.nan\n","                auprc = metrics.average_precision_score(y_true_binary, y_score_class)\n","\n","                auroc_scores.append(auroc)\n","                auprc_scores.append(auprc)\n","\n","            valid_auroc = ~np.isnan(auroc_scores)\n","            weighted_auroc = np.sum(np.array(auroc_scores)[valid_auroc] * class_weights[valid_auroc]) / np.sum(class_weights[valid_auroc])\n","            weighted_auprc = np.sum(np.array(auprc_scores) * class_weights) / np.sum(class_weights)\n","\n","            auroc_bootstrap.append(weighted_auroc)\n","            auprc_bootstrap.append(weighted_auprc)\n","\n","        auroc_ci = np.percentile(auroc_bootstrap, [2.5, 97.5])\n","        auprc_ci = np.percentile(auprc_bootstrap, [2.5, 97.5])\n","\n","        print(f\"\\n{label_name} - Bootstrapped Weighted Metrics:\")\n","        print(f\"wAUROC 95% CI: [{auroc_ci[0]:.4f}, {auroc_ci[1]:.4f}]\")\n","        print(f\"wAUPRC 95% CI: [{auprc_ci[0]:.4f}, {auprc_ci[1]:.4f}]\")\n","\n","        return auroc_ci, auprc_ci\n","\n","    except (FileNotFoundError, KeyError, ValueError) as e:\n","        print(f\"Error processing {csv_file_path}: {e}\")\n","        return None, None\n","\n","\n","# Run bootstrap evaluation\n","csv_files_with_labels = [\n","    ('/content/mimic_race_chexpert_race_v1_test.csv', 'CheXpert')\n","]\n","\n","for file_path, label in csv_files_with_labels:\n","    bootstrap_race_metrics(file_path, label)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EmfrQ8FpKr2h","executionInfo":{"status":"ok","timestamp":1748645151859,"user_tz":240,"elapsed":81999,"user":{"displayName":"Preetham Bachina","userId":"11894630684993396878"}},"outputId":"6b269ddd-bd67-4439-820a-4ca4eee7a5df"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","CheXpert - Bootstrapped Weighted Metrics:\n","wAUROC 95% CI: [0.8724, 0.8823]\n","wAUPRC 95% CI: [0.8755, 0.8846]\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import ast\n","from sklearn import metrics\n","from sklearn.preprocessing import LabelEncoder\n","import numpy as np\n","\n","# Standardized race/ethnicity categories\n","STANDARD_RACES = ['Asian', 'Black', 'Hispanic/Latino', 'Other', 'White']\n","\n","# Mapping from original labels to standardized labels\n","RACE_STANDARDIZATION = {\n","    'Asian': 'Asian',\n","    'Non-Hispanic Asian': 'Asian',\n","    'Black': 'Black',\n","    'Non-Hispanic Black': 'Black',\n","    'Hispanic/Latino': 'Hispanic/Latino',\n","    'Other': 'Other',\n","    'White': 'White',\n","    'Non-Hispanic White': 'White'\n","}\n","\n","def bootstrap_race_metrics(csv_file_path, label_name, n_iterations=1000, random_state=2025):\n","    try:\n","        df = pd.read_csv(csv_file_path)\n","        df['Race/Ethnicity_Probability'] = df['Race/Ethnicity_Probability'].apply(ast.literal_eval)\n","        df['Race/Ethnicity'] = df['Race/Ethnicity'].map(RACE_STANDARDIZATION)\n","        label_encoder = LabelEncoder()\n","        y_true_all = label_encoder.fit_transform(df['Race/Ethnicity'])\n","        y_score_all = np.array(df['Race/Ethnicity_Probability'].tolist())\n","        classes = label_encoder.classes_\n","        n_classes = len(classes)\n","\n","        data = pd.DataFrame({'y_true': y_true_all.tolist(), 'y_score': y_score_all.tolist()})\n","        rng = np.random.default_rng(seed=random_state)\n","\n","        # Store AUROC and AUPRC for weighted and each class\n","        auroc_bootstrap = []\n","        auprc_bootstrap = []\n","        per_class_aurocs = [[] for _ in range(n_classes)]\n","\n","        for _ in range(n_iterations):\n","            sample = data.sample(n=len(data), replace=True, random_state=rng.integers(1e9))\n","            y_true = np.array(sample['y_true'].tolist())\n","            y_score = np.array(sample['y_score'].tolist())\n","\n","            auroc_scores = []\n","            auprc_scores = []\n","            class_counts = np.bincount(y_true, minlength=n_classes)\n","            class_weights = class_counts / len(y_true)\n","\n","            for class_idx in range(n_classes):\n","                y_true_binary = (y_true == class_idx).astype(int)\n","\n","                # Special case for CheXpert \"Other\" class index 3\n","                if class_idx == 2 and label_name == 'CheXpert':\n","                    y_score_class = y_score[:, 4]\n","                else:\n","                    y_score_class = y_score[:, class_idx]\n","\n","                if len(np.unique(y_true_binary)) >= 2:\n","                    auroc = metrics.roc_auc_score(y_true_binary, y_score_class)\n","                else:\n","                    auroc = np.nan\n","                auprc = metrics.average_precision_score(y_true_binary, y_score_class)\n","\n","                auroc_scores.append(auroc)\n","                auprc_scores.append(auprc)\n","\n","                # Collect for CI computation\n","                per_class_aurocs[class_idx].append(auroc)\n","\n","            valid_auroc = ~np.isnan(auroc_scores)\n","            weighted_auroc = np.sum(np.array(auroc_scores)[valid_auroc] * class_weights[valid_auroc]) / np.sum(class_weights[valid_auroc])\n","            weighted_auprc = np.sum(np.array(auprc_scores) * class_weights) / np.sum(class_weights)\n","\n","            auroc_bootstrap.append(weighted_auroc)\n","            auprc_bootstrap.append(weighted_auprc)\n","\n","        # Compute weighted CIs\n","        auroc_ci = np.percentile(auroc_bootstrap, [2.5, 97.5])\n","        auprc_ci = np.percentile(auprc_bootstrap, [2.5, 97.5])\n","\n","        print(f\"\\n{label_name} - Bootstrapped Weighted Metrics:\")\n","        print(f\"wAUROC 95% CI: [{auroc_ci[0]:.4f}, {auroc_ci[1]:.4f}]\")\n","        print(f\"wAUPRC 95% CI: [{auprc_ci[0]:.4f}, {auprc_ci[1]:.4f}]\")\n","\n","        # Compute and print per-class AUROC CIs\n","        print(f\"\\n{label_name} - Per-Class AUROC 95% Confidence Intervals:\")\n","        for i, class_name in enumerate(classes):\n","            class_aurocs = [x for x in per_class_aurocs[i] if not np.isnan(x)]\n","            if len(class_aurocs) > 0:\n","                ci_low, ci_high = np.percentile(class_aurocs, [2.5, 97.5])\n","                print(f\"{class_name:<20}: [{ci_low:.4f}, {ci_high:.4f}]\")\n","            else:\n","                print(f\"{class_name:<20}: AUROC CI not computable (insufficient variation)\")\n","\n","        return auroc_ci, auprc_ci\n","\n","    except (FileNotFoundError, KeyError, ValueError) as e:\n","        print(f\"Error processing {csv_file_path}: {e}\")\n","        return None, None\n","\n","\n","# Run bootstrap evaluation\n","csv_files_with_labels = [\n","    ('/content/mimic_race_chexpert_race_v1_test.csv', 'CheXpert')\n","]\n","\n","for file_path, label in csv_files_with_labels:\n","    bootstrap_race_metrics(file_path, label)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N92U67lrSE6z","executionInfo":{"status":"ok","timestamp":1748645233820,"user_tz":240,"elapsed":81962,"user":{"displayName":"Preetham Bachina","userId":"11894630684993396878"}},"outputId":"aa9353c5-31dc-4f60-dff7-e67c9b30edae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","CheXpert - Bootstrapped Weighted Metrics:\n","wAUROC 95% CI: [0.8724, 0.8823]\n","wAUPRC 95% CI: [0.8755, 0.8846]\n","\n","CheXpert - Per-Class AUROC 95% Confidence Intervals:\n","Asian               : [0.8718, 0.8832]\n","Black               : [0.9042, 0.9191]\n","White               : [0.8687, 0.8795]\n"]}]}]}