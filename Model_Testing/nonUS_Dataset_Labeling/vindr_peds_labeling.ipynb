{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM/Gm4aHYIoEgZOQm5hVvDX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["This script goes through the DICOM images of the VinDr-PCXR dataset and extracts Age and Sex information for each image and stores them in a CSV file."],"metadata":{"id":"ILWEJhpk1yQG"}},{"cell_type":"code","source":["!chmod 600 ~/.passwd-s3fs"],"metadata":{"id":"da_A_ciufB2A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!apt install s3fs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gkIoLSoAfCvj","executionInfo":{"status":"ok","timestamp":1673116017913,"user_tz":300,"elapsed":1895,"user":{"displayName":"Preetham Bachina","userId":"11894630684993396878"}},"outputId":"5d64df6f-c82f-4c07-9e35-6bbb218cba6f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","s3fs is already the newest version (1.82-1).\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-460\n","Use 'apt autoremove' to remove it.\n","0 upgraded, 0 newly installed, 0 to remove and 20 not upgraded.\n"]}]},{"cell_type":"code","source":["!mkdir /s3\n","!s3fs um2ii-datasets /s3"],"metadata":{"id":"3RMpwOkHfDnz"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N5PdxHbZp645"},"outputs":[],"source":["import pandas as pd\n","import pydicom as dicom\n","import os\n","import cv2\n","import numpy as np\n","from PIL import Image, ImageOps\n","import pylibjpeg"]},{"cell_type":"code","source":["# Specify the .dcm folder path\n","folder_path = \"D:/Vindr_PCXR_Peds_Chest_X-Ray_Data/vindr-pcxr-an-open-large-scale-pediatric-chest-x-ray-dataset-for-interpretation-of-common-thoracic-diseases-1.0.0\"\n","# Specify the output jpg/png folder path\n","jpg_folder_path = 'D:/Vindr_PCXR_Peds_Chest_X-Ray_Data_Uncompressed'\n","train_images_path = os.listdir(os.path.join(folder_path, 'train'))\n","test_images_path = os.listdir(os.path.join(folder_path, 'test'))\n","paths = []\n","sex = []\n","age = []"],"metadata":{"id":"DcRCeBuXqa7o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(len(train_images_path))\n","print(len(test_images_path))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HoITW1gu1zYI","executionInfo":{"status":"ok","timestamp":1673553911329,"user_tz":300,"elapsed":6,"user":{"displayName":"Preetham Bachina","userId":"11894630684993396878"}},"outputId":"56531d5b-cab4-42b9-9e89-ccf2177349f1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["7728\n","1397\n"]}]},{"cell_type":"code","source":["for n, image in enumerate(train_images_path):\n","    ds = dicom.dcmread(os.path.join(folder_path, 'train', image))\n","    if ds.PhotometricInterpretation == \"MONOCHROME2\":\n","        new_image = ds.pixel_array.astype(float)\n","        scaled_image = (np.maximum(new_image, 0) / new_image.max()) * 255.0\n","        scaled_image = np.uint8(scaled_image)\n","        final_image = Image.fromarray(scaled_image)\n","        image = image.replace('.dicom', '.jpg')\n","        final_image.save(os.path.join(jpg_folder_path, image))\n","    else:\n","        new_image = ds.pixel_array.astype(float)\n","        scaled_image = (np.maximum(new_image, 0) / new_image.max()) * 255.0\n","        scaled_image = np.uint8(scaled_image)\n","        final_image = Image.fromarray(np.uint8() - scaled_image)\n","        image = image.replace('.dicom', '.jpg')\n","        final_image.save(os.path.join(jpg_folder_path, image))\n","    paths.append(image.replace('.dicom', '.jpg'))\n","    if ds.get('PatientSex') == None:\n","      sex.append('NaN')\n","    else:\n","      sex.append(ds.PatientSex)\n","    if ds.get('PatientAge') == None:\n","      age.append('NaN')\n","    else:\n","      age.append(ds.PatientAge)\n","    if n % 50 == 0:\n","        print('{} image converted'.format(n))"],"metadata":{"id":"Cu_PaH4gqdNc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1673555424709,"user_tz":300,"elapsed":1512432,"user":{"displayName":"Preetham Bachina","userId":"11894630684993396878"}},"outputId":"22d6a85e-d27a-449f-925b-4732fc0a91c0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0 image converted\n","50 image converted\n","100 image converted\n","150 image converted\n","200 image converted\n"]},{"output_type":"stream","name":"stderr","text":["C:\\Users\\pree1\\anaconda3\\envs\\international_validity\\lib\\site-packages\\openjpeg\\utils.py:209: UserWarning: The (0028,0101) Bits Stored value '12' in the dataset does not match the component precision value '16' found in the JPEG 2000 data. It's recommended that you change the Bits Stored value to produce the correct output\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["250 image converted\n","300 image converted\n","350 image converted\n","400 image converted\n","450 image converted\n","500 image converted\n","550 image converted\n","600 image converted\n","650 image converted\n","700 image converted\n","750 image converted\n","800 image converted\n","850 image converted\n","900 image converted\n","950 image converted\n","1000 image converted\n","1050 image converted\n","1100 image converted\n","1150 image converted\n","1200 image converted\n","1250 image converted\n","1300 image converted\n","1350 image converted\n","1400 image converted\n","1450 image converted\n","1500 image converted\n","1550 image converted\n","1600 image converted\n","1650 image converted\n","1700 image converted\n","1750 image converted\n","1800 image converted\n","1850 image converted\n","1900 image converted\n","1950 image converted\n"]},{"output_type":"stream","name":"stderr","text":["C:\\Users\\pree1\\anaconda3\\envs\\international_validity\\lib\\site-packages\\pydicom\\pixel_data_handlers\\numpy_handler.py:217: UserWarning: The odd length pixel data is missing a trailing padding byte\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["2000 image converted\n","2050 image converted\n","2100 image converted\n","2150 image converted\n","2200 image converted\n","2250 image converted\n","2300 image converted\n","2350 image converted\n","2400 image converted\n","2450 image converted\n","2500 image converted\n","2550 image converted\n","2600 image converted\n","2650 image converted\n","2700 image converted\n","2750 image converted\n","2800 image converted\n","2850 image converted\n","2900 image converted\n","2950 image converted\n","3000 image converted\n","3050 image converted\n","3100 image converted\n","3150 image converted\n","3200 image converted\n","3250 image converted\n","3300 image converted\n","3350 image converted\n","3400 image converted\n","3450 image converted\n","3500 image converted\n","3550 image converted\n","3600 image converted\n","3650 image converted\n","3700 image converted\n","3750 image converted\n","3800 image converted\n","3850 image converted\n","3900 image converted\n","3950 image converted\n","4000 image converted\n","4050 image converted\n","4100 image converted\n","4150 image converted\n","4200 image converted\n","4250 image converted\n","4300 image converted\n","4350 image converted\n","4400 image converted\n","4450 image converted\n","4500 image converted\n","4550 image converted\n","4600 image converted\n","4650 image converted\n","4700 image converted\n","4750 image converted\n","4800 image converted\n","4850 image converted\n","4900 image converted\n","4950 image converted\n","5000 image converted\n","5050 image converted\n","5100 image converted\n","5150 image converted\n","5200 image converted\n","5250 image converted\n","5300 image converted\n","5350 image converted\n","5400 image converted\n","5450 image converted\n","5500 image converted\n","5550 image converted\n","5600 image converted\n","5650 image converted\n","5700 image converted\n","5750 image converted\n","5800 image converted\n","5850 image converted\n","5900 image converted\n","5950 image converted\n","6000 image converted\n","6050 image converted\n","6100 image converted\n","6150 image converted\n","6200 image converted\n","6250 image converted\n","6300 image converted\n","6350 image converted\n","6400 image converted\n","6450 image converted\n","6500 image converted\n","6550 image converted\n","6600 image converted\n","6650 image converted\n","6700 image converted\n","6750 image converted\n","6800 image converted\n","6850 image converted\n","6900 image converted\n","6950 image converted\n","7000 image converted\n","7050 image converted\n","7100 image converted\n","7150 image converted\n","7200 image converted\n","7250 image converted\n","7300 image converted\n","7350 image converted\n","7400 image converted\n","7450 image converted\n","7500 image converted\n","7550 image converted\n","7600 image converted\n","7650 image converted\n","7700 image converted\n"]}]},{"cell_type":"code","source":["for n, image in enumerate(test_images_path):\n","    ds = dicom.dcmread(os.path.join(folder_path, 'test', image))\n","    if ds.PhotometricInterpretation == \"MONOCHROME2\":\n","        new_image = ds.pixel_array.astype(float)\n","        scaled_image = (np.maximum(new_image, 0) / new_image.max()) * 255.0\n","        scaled_image = np.uint8(scaled_image)\n","        final_image = Image.fromarray(scaled_image)\n","        image = image.replace('.dicom', '.jpg')\n","        final_image.save(os.path.join(jpg_folder_path, image))\n","    else:\n","        new_image = ds.pixel_array.astype(float)\n","        scaled_image = (np.maximum(new_image, 0) / new_image.max()) * 255.0\n","        scaled_image = np.uint8(scaled_image)\n","        final_image = Image.fromarray(np.uint8() - scaled_image)\n","        image = image.replace('.dicom', '.jpg')\n","        final_image.save(os.path.join(jpg_folder_path, image))\n","    paths.append(image.replace('.dicom', '.jpg'))\n","    if ds.get('PatientSex') == None:\n","      sex.append('NaN')\n","    else:\n","      sex.append(ds.PatientSex)\n","    if ds.get('PatientAge') == None:\n","      age.append('NaN')\n","    else:\n","      age.append(ds.PatientAge)\n","\n","    if n % 50 == 0:\n","        print('{} image converted'.format(n))\n","\n","vindr_df= pd.DataFrame(paths, columns = ['Path'])\n","vindr_df['Sex'] = sex\n","vindr_df['Age'] = age\n","vindr_df.to_csv('D:/Vindr_PCXR_Peds_Chest_X-Ray_Data_Uncompressed/vinDR_peds_labels.csv', index=False)"],"metadata":{"id":"mSssRoFC4SZH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1673555748524,"user_tz":300,"elapsed":323813,"user":{"displayName":"Preetham Bachina","userId":"11894630684993396878"}},"outputId":"9c24aafb-e5d4-42f4-a458-3c0ba659833b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0 image converted\n","50 image converted\n","100 image converted\n","150 image converted\n","200 image converted\n","250 image converted\n","300 image converted\n","350 image converted\n","400 image converted\n","450 image converted\n","500 image converted\n","550 image converted\n","600 image converted\n","650 image converted\n","700 image converted\n","750 image converted\n","800 image converted\n","850 image converted\n","900 image converted\n","950 image converted\n","1000 image converted\n","1050 image converted\n","1100 image converted\n","1150 image converted\n","1200 image converted\n","1250 image converted\n","1300 image converted\n","1350 image converted\n"]}]},{"cell_type":"code","source":["df = pd.read_csv('D:/Vindr_PCXR_Peds_Chest_X-Ray_Data_Uncompressed/vinDR_peds_labels.csv')\n","df.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LVdpXKMq7VSC","executionInfo":{"status":"ok","timestamp":1673555748547,"user_tz":300,"elapsed":21,"user":{"displayName":"Preetham Bachina","userId":"11894630684993396878"}},"outputId":"4245b13a-bd4e-4811-b172-10435bdad6be"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(9125, 3)"]},"metadata":{},"execution_count":20}]}]}